{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ebc682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:23:46.534880: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 16:23:46.903974: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-06 16:23:46.904017: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-06 16:23:48.120567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-06 16:23:48.120669: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-06 16:23:48.120681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeca9680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'70,3948,2,1255219128' b'188,653,2,1025333400'\n",
      " b'243,103249,2,1464280162' b'359,3578,2,974700907'\n",
      " b'426,1500,2,1371502543' b'440,3022,2,1231472902'\n",
      " b'446,2861,2,1017900083' b'626,2162,2,1002897585' b'634,1006,2,865372001'\n",
      " b'700,46578,2,1350795469' b'734,3203,2,992217420'\n",
      " b'1044,2406,2,944907698' b'1332,1198,2,1529895670'\n",
      " b'1367,1037,2,1185835950' b'1409,5530,2,1288302165'\n",
      " b'1459,1183,2,889019866'], shape=(16,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TextLineDataset([\"gs://mgaiduk-us-central1/ratings/csv_gzip/part000000000000\"], compression_type=\"GZIP\")\n",
    "for line in dataset.batch(16): # batching added to demonstrate that parsing works on higher dimensional tensors\n",
    "    break\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76de1cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
       " array([  70,  188,  243,  359,  426,  440,  446,  626,  634,  700,  734,\n",
       "        1044, 1332, 1367, 1409, 1459])>,\n",
       " <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
       " array([  3948,    653, 103249,   3578,   1500,   3022,   2861,   2162,\n",
       "          1006,  46578,   3203,   2406,   1198,   1037,   5530,   1183])>,\n",
       " <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       " array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
       " array([1255219128, 1025333400, 1464280162,  974700907, 1371502543,\n",
       "        1231472902, 1017900083, 1002897585,  865372001, 1350795469,\n",
       "         992217420,  944907698, 1529895670, 1185835950, 1288302165,\n",
       "         889019866])>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaults = [tf.constant(0, dtype=tf.int64),\n",
    "           tf.constant(0, dtype=tf.int64),\n",
    "           tf.constant(0, dtype=tf.float32),\n",
    "           tf.constant(0, dtype=tf.int64)]\n",
    "csv_row = tf.io.decode_csv(line, defaults)\n",
    "csv_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e68dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'userId': <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
       "  array([  70,  188,  243,  359,  426,  440,  446,  626,  634,  700,  734,\n",
       "         1044, 1332, 1367, 1409, 1459])>,\n",
       "  'movieId': <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
       "  array([  3948,    653, 103249,   3578,   1500,   3022,   2861,   2162,\n",
       "           1006,  46578,   3203,   2406,   1198,   1037,   5530,   1183])>},\n",
       " {'label': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "  array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        dtype=float32)>})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def decode_fn(csv_line):\n",
    "    defaults = [tf.constant(0, dtype=tf.int64),\n",
    "           tf.constant(0, dtype=tf.int64),\n",
    "           tf.constant(0, dtype=tf.float32),\n",
    "           tf.constant(0, dtype=tf.int64)]\n",
    "    csv_row = tf.io.decode_csv(csv_line, defaults)\n",
    "    features = {}\n",
    "    features[\"userId\"] = csv_row[0]\n",
    "    features[\"movieId\"] = csv_row[1]\n",
    "    labels = {\n",
    "        \"label\": csv_row[2]\n",
    "    }\n",
    "    return (features, labels)\n",
    "dataset = tf.data.TextLineDataset([\"gs://mgaiduk-us-central1/ratings/csv_gzip/part000000000000\"],\n",
    "                                  compression_type=\"GZIP\").batch(16, drop_remainder=True).map(decode_fn)\n",
    "for elem in dataset:\n",
    "    break\n",
    "elem # take a look at the resulting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88400611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'userId': <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
       "  array([   5,  154,  226,  600,  689,  717,  810,  909, 1208, 1409, 1847,\n",
       "         2071, 2105, 2177, 2429, 2476])>,\n",
       "  'movieId': <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
       "  array([  191, 69526,   736,   435,  7759,  1240,  2087,  1527,   158,\n",
       "          1722,  1037,   480,  1261,  6290,    39,  4037])>},\n",
       " {'label': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "  array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        dtype=float32)>})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = tf.data.Dataset.list_files(\"gs://mgaiduk-us-central1/ratings/csv_gzip/part*\", shuffle=True, seed=42)\n",
    "dataset = tf.data.TextLineDataset(filenames,\n",
    "                                  compression_type=\"GZIP\").batch(16, drop_remainder=True).map(decode_fn)\n",
    "for elem in dataset:\n",
    "    break\n",
    "elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a602c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'userId': <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
       "  array([   5,  154,  226,  600,  689,  717,  810,  909, 1208, 1409, 1847,\n",
       "         2071, 2105, 2177, 2429, 2476])>,\n",
       "  'movieId': <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
       "  array([  191, 69526,   736,   435,  7759,  1240,  2087,  1527,   158,\n",
       "          1722,  1037,   480,  1261,  6290,    39,  4037])>},\n",
       " {'label': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "  array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        dtype=float32)>})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = None # will not be none in distributed strategy, see later\n",
    "def make_dataset_fn(path):\n",
    "    dataset = tf.data.TextLineDataset([path], compression_type=\"GZIP\")\n",
    "    dataset = dataset\\\n",
    "        .batch(16, drop_remainder=True)\\\n",
    "    .map(decode_fn)\n",
    "    return dataset\n",
    "filenames = tf.data.Dataset.list_files(\"gs://mgaiduk-us-central1/ratings/csv_gzip/part*\", shuffle=True, seed=42)\n",
    "if ctx and ctx.num_input_pipelines > 1:\n",
    "    filenames = filenames.shard(ctx.num_input_pipelines, ctx.input_pipeline_id)\n",
    "dataset = filenames.interleave(make_dataset_fn)\n",
    "for elem in dataset:\n",
    "    break\n",
    "elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520926b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
