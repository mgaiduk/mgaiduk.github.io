<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Chapter 3. Proper input pipeline and the model - Tensorflow for recsys</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="chapter_1.html"><strong aria-hidden="true">1.</strong> Chapter 1. What is this book about</a></li><li class="chapter-item expanded "><a href="chapter_2.html"><strong aria-hidden="true">2.</strong> Chapter 2. First glance at the data</a></li><li class="chapter-item expanded "><a href="chapter_3.html" class="active"><strong aria-hidden="true">3.</strong> Chapter 3. Proper input pipeline and the model</a></li><li class="chapter-item expanded "><a href="chapter_4.html"><strong aria-hidden="true">4.</strong> Chapter 4. The model</a></li><li class="chapter-item expanded "><a href="chapter_5.html"><strong aria-hidden="true">5.</strong> Chapter 5. Tidying up</a></li><li class="chapter-item expanded "><a href="chapter_6.html"><strong aria-hidden="true">6.</strong> Chapter 6. Training on TPU</a></li><li class="chapter-item expanded "><a href="chapter_7.html"><strong aria-hidden="true">7.</strong> Chapter 7. LazyAdam, or some hacks for training speed</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Tensorflow for recsys</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="chapter-3-proper-input-pipeline-and-the-model"><a class="header" href="#chapter-3-proper-input-pipeline-and-the-model">Chapter 3. Proper input pipeline and the model</a></h1>
<p>In the last chapter, we discussed various data storing formats a little bit, and got to take a first look at the data, still not parsed, but already represented as a tensor.<br />
In this chapter, we will build a proper data pipeline, reading data from all our files, parsing it and properly handling sharding during distributed training.</p>
<h3 id="csv-data-parsing"><a class="header" href="#csv-data-parsing">CSV data parsing</a></h3>
<p>In the last chapter, we had roughly the following code:</p>
<pre><code>dataset = tf.data.TextLineDataset([&quot;gs://mgaiduk-us-central1/ratings/csv_gzip/part000000000000&quot;], compression_type=&quot;GZIP&quot;)
for line in dataset.batch(16): # batching added to demonstrate that parsing works on higher dimensional tensors
    break
print(line)
</code></pre>
<p>That reads the data from just one file out of several for our exported table, and does no parsing.</p>
<p>Here is how we can parse it:</p>
<pre><code>defaults = [tf.constant(0, dtype=tf.int64),
           tf.constant(0, dtype=tf.int64),
           tf.constant(0, dtype=tf.float32),
           tf.constant(0, dtype=tf.int64)]
csv_row = tf.io.decode_csv(line, defaults)
csv_row
</code></pre>
<p><code>[&lt;tf.Tensor: shape=(16,), dtype=int64, numpy=array([  70,  188,  243,  359,  426,  440,  446,  626,  634,  700,  734,1044, 1332, 1367, 1409, 1459])&gt;,</code><br />
<code>&lt;tf.Tensor: shape=(16,), dtype=int64, numpy=array([  3948,    653, 103249,   3578,   1500,   3022,   2861,   2162,1006,  46578,   3203,   2406,   1198,   1037,   5530,   1183])&gt;,</code><br />
<code>&lt;tf.Tensor: shape=(16,), dtype=float32, numpy=array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],dtype=float32)&gt;,</code><br />
<code>&lt;tf.Tensor: shape=(16,), dtype=int64, numpy=array([1255219128, 1025333400, 1464280162,  974700907, 1371502543,1231472902, 1017900083, 1002897585,  865372001, 1350795469,992217420,  944907698, 1529895670, 1185835950, 1288302165,889019866])&gt;]</code></p>
<p>We pass <code>defaults</code> to it to signify which data types are expected, and to use in case an entire column is missing (though it is rather hard to imagine in CSV)</p>
<p>To be able to just call <code>model.fit(training_dataset)</code> on our data, we need to turn it into a dataset, and have it output a tuple with 2 values: features and labels. It is also common to represent features as a dictionary, to know what column means what, and to be able to connect it to model code. Here is the code that does that:</p>
<pre><code>@tf.function
def decode_fn(csv_line):
    defaults = [tf.constant(0, dtype=tf.int64),
           tf.constant(0, dtype=tf.int64),
           tf.constant(0, dtype=tf.float32),
           tf.constant(0, dtype=tf.int64)]
    csv_row = tf.io.decode_csv(csv_line, defaults)
    features = {}
    features[&quot;userId&quot;] = csv_row[0]
    features[&quot;movieId&quot;] = csv_row[1]
    labels = {
        &quot;label&quot;: csv_row[2]
    }
    return (features, labels)
dataset = tf.data.TextLineDataset([&quot;gs://mgaiduk-us-central1/ratings/csv_gzip/part000000000000&quot;],
                                  compression_type=&quot;GZIP&quot;).batch(16, drop_remainder=True).map(decode_fn)
for elem in dataset:
    break
elem # take a look at the resulting data
</code></pre>
<p><code>dataset.map()</code> function takes a dataset and applies a function to each row.<br />
We do the batching first, and then do the parsing. This is because we want to spend less time in our own, python code, and more time in optimized tensorflow intrinsics. Because of this, it is better to turn small tensors into big, high-dimensional tensors first, to have our python code benefit from vectorization.</p>
<p>Another interesting detail is the works of @tf.function. It does roughly the following: upon calling the function for the first time, TF engine sees tensor inputs with concrete shapes, and compiles the code into an execution graph, treating all non-tensor inputs as contants. If non-tensor inputs are not constant, say, you have some training-dependable variable in the pipeline, graph compilation will happen every time, which will probably be slower then just running the python code. All side effects are also executed on graph compile time only. This means that you can insert print statements in the desired places in your code, and see what exactly is being passed around, but only on the first step of your execution.</p>
<p>If tensor shapes change during execution, the training will probably crush (at least on TPU). This is why we have `.batch(16, drop_remainder=True). Normally, when batching limited size dataset, last batch is slightly smaller. We don't want our model to crush right at the end, so we just drop that remainder.</p>
<p>Next, we need to read all the files for our dataset, not just the one file. We could do it like this:</p>
<pre><code>filenames = tf.data.Dataset.list_files(&quot;gs://mgaiduk-us-central1/ratings/csv_gzip/part*&quot;, shuffle=True, seed=42)
dataset = tf.data.TextLineDataset(filenames,
                                  compression_type=&quot;GZIP&quot;).batch(16, drop_remainder=True).map(decode_fn)
for elem in dataset:
    break
elem
</code></pre>
<p><code>TextLineDataset</code> api is smart enough to accept a list of files, or even a dataset that outputs filenames. The only reason NOT to do it like that is proper sharding, which should be done like this instead:</p>
<pre><code>ctx = None # will not be none in distributed strategy, see later
def make_dataset_fn(path):
    dataset = tf.data.TextLineDataset([path], compression_type=&quot;GZIP&quot;)
    dataset = dataset\
        .batch(16, drop_remainder=True)\
    .map(decode_fn)
    return dataset
filenames = tf.data.Dataset.list_files(&quot;gs://mgaiduk-us-central1/ratings/csv_gzip/part*&quot;, shuffle=True, seed=42)
if ctx and ctx.num_input_pipelines &gt; 1:
    filenames = filenames.shard(ctx.num_input_pipelines, ctx.input_pipeline_id)
dataset = filenames.interleave(make_dataset_fn)
for elem in dataset:
    break
elem
</code></pre>
<p><code>tf.data.Dataset.list_files</code> creates a dataset with all filenames matching a pattern.<br />
When we train under a distributed strategy, we will receive a ctx with information about total number of shards and current shard index. Under data parallelism methodology, we want each shard to read its own portion of data. It can be achieved by <code>tf.data.Dataset.shard()</code> function, that takes total number of batches and shard idx as input. It works like this: it reads the dataset and skips all the data except 1/nths. We don't want to actually read and parse all that skipped data; that is why we call this method on filenames dataset.</p>
<p>Finally, we want to add some dataset stuff to make sure input pipeline is not a bottleneck:</p>
<pre><code>ctx = None # will not be none in distributed strategy, see later
filenames = tf.data.Dataset.list_files(&quot;gs://mgaiduk-us-central1/ratings/csv_gzip/part*&quot;, shuffle=True, seed=42)
if ctx and ctx.num_input_pipelines &gt; 1:
    filenames = filenames.shard(ctx.num_input_pipelines, ctx.input_pipeline_id)
dataset = filenames.interleave(make_dataset_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False, cycle_length=8)
dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)

for elem in dataset:
    break
elem
</code></pre>
<p>New things here:</p>
<ol>
<li>
<p>We call <code>prefetch</code> dataset method. Without it, one iteration of training loop will call dataset processing code to fetch 1 element, then perform a model training step, then call dataset function and so on. If you are doing your training on a multi-core machine, all those extra cores will probably just do nothing during dataset processing step. Having prefetch allows you to process dataset and do model training at the same time. AUTOTUNE parameter usually works, but if you are really interested in trying out different values - you can put some number here.<br />
Important to note that we do <code>prefetch</code> in the very end, making sure we prefetch fully parsed, batched data.</p>
</li>
<li>
<p>dataset.interleave got 2 new parameters: num_parallel_calls and cycle_length. They both are required for parallelism because of how parallel computing works in <code>interleave</code> calls. This is the second crucial step in making sure your input pipeline is not a bottleneck. If your parsing is done on just one core, having prefetch will not be enough to fetch new data with enough speed. Parallel dataset execution makes sure that you give enough cores for the task</p>
</li>
<li>
<p><code>deterministic=False</code> in <code>interleave</code>. In theory, this might speed up input data pipeline, because it allows dataset executor to output results from multiple parallel calls as soon as they are ready. However, if you have prefetch and parallel calls, you probably won't notice latency differences. Important thing is, if you are doing distributed training, to have sharding done BEFORE any non-determinism in the pipeline, otherwise the shards will train on random, partially intersecting parts of data. </p>
</li>
</ol>
<p>Code for this chapter is available as a <a href="https://github.com/mgaiduk/mgaiduk.github.io/blob/main/my-first-book/src/code/chapter3/proper_dataset_parsing.ipynb">jupyter notebook</a>.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="chapter_2.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="chapter_4.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="chapter_2.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="chapter_4.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
